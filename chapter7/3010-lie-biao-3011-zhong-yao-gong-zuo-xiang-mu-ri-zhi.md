#### ES集群深入数据有效性进行优化

时间：2019年1月-2019年3月

lbs索引里面，province和city为0的记录是没有任何意义的，可以清理掉。

active/online索引里面，timestamp超过一定范围的，都是没有意义的数据，可以清理掉。

另外，修改业务逻辑，避免产生新的无效数据。

效果一：lbs数据总共约100亿条，清理无效数据31.5亿条，占比30%。

---

#### 广播缓存历史非活跃uid数据清理

时间：2019年2月-2019年3月

广播缓存占用内存空间持续增长，使用的是redis的set结构，只增不减，但是实际上里面有很多是不活跃的僵尸用户，合理地清理掉这些用户，对于节约内存空间、提高查询效率都非常有帮助。

---

#### CouchBase热点数据导致集群踢出节点

时间：2019年1月-2019年2月

现象：一个由8个节点组成的CouchBase集群，发现总是频繁地出现某一节点突然被自动踢出集群，然后另一机器CPU负载超高的现象，导致整个集群响应非常慢。一段时间内改现象反复出现。

排查：替换过机器、重建过集群，问题还是重复出现。基本排除硬件问题。

定位：发现是一个用户针对某个uid（在CouchBase中是key）做压力测试，该uid是虚拟uid，峰值达到3w-4w/s的写入量，导致某个节点过热，从而被踢出集群。第一个节点被提出集群后，由于副本集设置为1，CouchBase的安全机制确保不会再自动踢掉第二个节点，所以导致另一个节点CPU占用超高，进而导致整个集群几乎不可用。

解决：在业务逻辑处做判断，当请求量达到一定程度时，做服务降级处理，丢弃部分数据。

---

#### 某ES集群优化

时间：2019年3月

现象：4台机器组成的ES集群，业务侧反馈**查询非常慢**，但是看机器监控压力都很小。

查找和解决：客户端连接的线程池设置为200，而我们的服务器是16核的，过大的线程池数量导致查询效率低下。通过修改线程池大小，线程数不超过25： 查询不要超过25，写入不要超过 16。业务侧做了上述修改之后，再无类似的问题出现。

---

时间：2019年7月

OpenStack的多个VM，超分了CPU资源，及时某一个VM的CPU是空闲的，也会引起整个物理机上其他VM的CPU出现steal的情况。把空闲的VM的CPU降下去，其他VM也明显有了改善。

---



